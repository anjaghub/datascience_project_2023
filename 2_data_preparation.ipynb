{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Climate Change - Data Preparation\n",
    "Supervision: Prof. Dr. Jan Fabian Ehmke\n",
    "\n",
    "Group members: Britz Luis, Huber Anja, Krause Felix Elias, Preda Yvonne-Nadine\n",
    "\n",
    "Time: Summer term 2023 \n",
    "\n",
    "Data: https://www.kaggle.com/datasets/pavellexyr/the-reddit-climate-change-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "raw_comments = pd.read_csv('data/the-reddit-climate-change-dataset-comments.csv',nrows=50000)\n",
    "raw_posts = pd.read_csv('data/the-reddit-climate-change-dataset-posts.csv',nrows= 50000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty, removed and deleted entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean post data set from empty posts, removed posts, deleted posts\n",
    "clean_posts = raw_posts.drop(raw_posts[raw_posts['selftext'] == '[removed]'].index)\n",
    "clean_posts = clean_posts.drop(clean_posts[clean_posts['selftext'] == '[deleted]'].index)\n",
    "clean_posts = clean_posts.dropna(subset=['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean comment dataset from empty comments\n",
    "clean_comments = raw_comments.dropna(subset=['body'], how='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates in post and comment dataset\n",
    "clean_posts = clean_posts.drop_duplicates(subset=[\"selftext\",\"type\"])\n",
    "clean_comments = clean_comments.drop_duplicates(subset=[\"body\",\"type\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort out the word climate change in comment and post dataset\n",
    "deleted_words = (\"climate\",\"change\")\n",
    "\n",
    "for x in deleted_words:\n",
    "    clean_posts[\"selftext\"] = clean_posts[\"selftext\"].str.replace(x, \"\", case=False)\n",
    "    clean_posts[\"title\"] = clean_posts[\"title\"].str.replace(x, \"\", case=False)\n",
    "    clean_comments[\"body\"] = clean_comments[\"body\"].str.replace(x, \"\", case=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_subreddits = ['memebot9000', \n",
    "                  'spacenewsbot', \n",
    "                  'removalbot', \n",
    "                  'u_ignorantbotkin4ho', \n",
    "                  'botsrights', \n",
    "                  'gildedbot', \n",
    "                  'open_bots_test', \n",
    "                  'rcbredditbot', \n",
    "                  'newsbotmarket', \n",
    "                  'alt_source_bot_log', \n",
    "                  'steamiebot', \n",
    "                  'modbot_staging',\n",
    "                  'testanimalsupportbot', \n",
    "                  'u_udemy_sample_bot', \n",
    "                  'newsbottmt', \n",
    "                  'bottownfriends', \n",
    "                  'airsoft_bot', \n",
    "                  'wikileaksemailbot', \n",
    "                  'foreveralonebots', \n",
    "                  'botterminator', \n",
    "                  'bottown2', \n",
    "                  'bottown_polibot', \n",
    "                  'bottowngarden', \n",
    "                  'havoc_bot', \n",
    "                  'botrequests', \n",
    "                  'sentimentviewbot', \n",
    "                  'newsbotscience', \n",
    "                  'u_commonmisspellingbot', \n",
    "                  'dogetipbot', \n",
    "                  'resistbot', \n",
    "                  'newsbotfunding', \n",
    "                  'ebolanewsbot', \n",
    "                  'gwcoepbot', \n",
    "                  'uknewsbyabot', \n",
    "                  'u_flamboyantbotoshrx', \n",
    "                  'laserlikebot', \n",
    "                  'repostsleuthbot', \n",
    "                  'interfaithbotdialogue', \n",
    "                  'articlebot', \n",
    "                  'potuswatchbot', \n",
    "                  'pulsarbot', \n",
    "                  'mimeticsbot', \n",
    "                  'cryptobots', \n",
    "                  'wutbotposts', \n",
    "                  'bottesting', \n",
    "                  'botbotread', \n",
    "                  'cleverbot', \n",
    "                  'u_anticensor_bot', \n",
    "                  'trollbot', \n",
    "                  'brokentranslatebot', \n",
    "                  'newsbiasbot', \n",
    "                  'sexpollbottest', \n",
    "                  'bottalks', \n",
    "                  'bitnewsbot', \n",
    "                  'gbpolbot', \n",
    "                  'rssbot', \n",
    "                  'botsscrewingup', \n",
    "                  'u_dicebotbtc', \n",
    "                  'u_userleansbot', \n",
    "                  'islamicstatenewsbot', \n",
    "                  'u_moebot12', \n",
    "                  'webbot', \n",
    "                  'pew_bot_memes', \n",
    "                  'u_zukbot', \n",
    "                  'u_bot4bot', \n",
    "                  'stabbot', \n",
    "                  'u_yangpolicyinfo_bot', \n",
    "                  'subredditsummarybot', \n",
    "                  'bot4bottesting', \n",
    "                  'travsbots', \n",
    "                  'spooktoberbot', \n",
    "                  'trollabot', \n",
    "                  'printrbot', \n",
    "                  'bottown1', \n",
    "                  'kzreminderbotsub', \n",
    "                  'bottown', \n",
    "                  'newsbotbot', \n",
    "                  'gifbot', \n",
    "                  'uvabot', \n",
    "                  'cfbotpolitics', \n",
    "                  'nwordcountbot', \n",
    "                  'quizzybot', \n",
    "                  'israelnewsbot', \n",
    "                  'popularnewsbot', \n",
    "                  'monkeynewsbot', \n",
    "                  'thelinkfixerbot', \n",
    "                  'atheismbot', \n",
    "                  'inspirobotbot', \n",
    "                  'testingground4bots', \n",
    "                  'buzzfeedbot', \n",
    "                  'isreactionarybot', \n",
    "                  'blenderbot', \n",
    "                  'talkwithgpt2bots', \n",
    "                  'bottown22', \n",
    "                  'twitter_bot', \n",
    "                  'autowikibot', \n",
    "                  'elsbot']\n",
    "\n",
    "for i in bot_subreddits:\n",
    "    clean_comments = clean_comments[~clean_comments['subreddit.name'].str.contains(i)]\n",
    "    clean_posts = clean_posts[~clean_posts['subreddit.name'].str.contains(i)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date and time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new columns with date and time information\n",
    "clean_posts['created_date'] = pd.to_datetime(clean_posts['created_utc'], utc=True, unit='s').dt.strftime('%Y-%m-%d')\n",
    "clean_posts['created_day'] = pd.to_datetime(clean_posts['created_utc'], utc=True, unit='s').dt.strftime('%d')\n",
    "clean_posts['created_month'] = pd.to_datetime(clean_posts['created_utc'], utc=True, unit='s').dt.strftime('%m')\n",
    "clean_posts['created_year'] = pd.to_datetime(clean_posts['created_utc'], utc=True, unit='s').dt.strftime('%Y')\n",
    "clean_posts['created_time'] = pd.to_datetime(clean_posts['created_utc'], utc=True, unit='s').dt.strftime('%H:%M:%S')\n",
    "\n",
    "clean_comments['created_date'] = pd.to_datetime(clean_comments['created_utc'], utc=True, unit='s').dt.strftime('%Y-%m-%d')\n",
    "clean_comments['created_day'] = pd.to_datetime(clean_comments['created_utc'], utc=True, unit='s').dt.strftime('%d')\n",
    "clean_comments['created_month'] = pd.to_datetime(clean_comments['created_utc'], utc=True, unit='s').dt.strftime('%m')\n",
    "clean_comments['created_year'] = pd.to_datetime(clean_comments['created_utc'], utc=True, unit='s').dt.strftime('%Y')\n",
    "clean_comments['created_time'] = pd.to_datetime(clean_comments['created_utc'], utc=True, unit='s').dt.strftime('%H:%M:%S')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output CSV file with relevant data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
