{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DANGEROUS TERRITORY:\n",
    "This notebook can allocate a lot of disk space and needs some processing power (ideally available CUDA GPU)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Climate Change - Modeling Sentiment & Emotion\n",
    "Supervision: Prof. Dr. Jan Fabian Ehmke\n",
    "\n",
    "Group members: Britz Luis, Huber Anja, Krause Felix Elias, Preda Yvonne-Nadine\n",
    "\n",
    "Time: Summer term 2023 \n",
    "\n",
    "Data: https://www.kaggle.com/datasets/pavellexyr/the-reddit-climate-change-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline # Protobuf version <4 (e.g. 3.20.3) might be needed!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import multiprocessing.dummy as mp \n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found: NVIDIA GeForce GTX 1060 6GB\n",
      "### \n",
      " WARNING: YOU WILL TRAIN ON DETECTED GPU \n",
      "###\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA device found: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    batch_size = 8\n",
    "    print(\"### \\n WARNING: YOU WILL TRAIN ON DETECTED GPU \\n###\")\n",
    "else:\n",
    "    batch_size = 1\n",
    "    device = -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of final dataset\n",
    "\n",
    "# df2 = pd.read_csv(\"data/comments2.csv\", header=0)\n",
    "# df2 = df2.dropna()\n",
    "# df2.head(3)\n",
    "\n",
    "# df = df.sort_values(by=\"id\").reset_index()\n",
    "# df2 = df2.sort_values(by=\"id\").reset_index()\n",
    "\n",
    "# df[\"body_clean_full\"] = df2.body_clean\n",
    "# df[\"id_2\"] = df2.id\n",
    "# print(sum(df.id != df.id_2))\n",
    "\n",
    "# df = df.drop([\"index\", \"id_2\", \"body_clean\"], axis=1)\n",
    "# df[\"body_clean_full\"] = [i.replace(\"\\n\", \" \") for i in df.body_clean_full]\n",
    "\n",
    "\n",
    "# Load compressed data\n",
    "#df = pd.read_csv(\"data/comments_preprocessed.gzip\", compression=\"gzip\", header=0, skiprows=0, nrows=11000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>subreddit.nsfw</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_time</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_most_used_words</th>\n",
       "      <th>body_clean_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0i14fb</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>False</td>\n",
       "      <td>1.262306e+09</td>\n",
       "      <td>https://old.reddit.com/r/AskReddit/comments/ak...</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>00:34:07</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_climate_people_global_warming</td>\n",
       "      <td>climate - people - global - warming - just - s...</td>\n",
       "      <td>should be \"San Diego Weatherman has an opinion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0i195b</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>1.262313e+09</td>\n",
       "      <td>https://old.reddit.com/r/worldnews/comments/ak...</td>\n",
       "      <td>0.4754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>02:30:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0_people_just_climate_global</td>\n",
       "      <td>people - just - climate - global - don - like ...</td>\n",
       "      <td>Both Iggy and Harper would have marched us int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0i1a0w</td>\n",
       "      <td>environment</td>\n",
       "      <td>False</td>\n",
       "      <td>1.262314e+09</td>\n",
       "      <td>https://old.reddit.com/r/environment/comments/...</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>02:54:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0_people_just_climate_global</td>\n",
       "      <td>people - just - climate - global - don - like ...</td>\n",
       "      <td>A man who though a moderate Tory , has a mixed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id subreddit.name  subreddit.nsfw   created_utc  \\\n",
       "0  c0i14fb      askreddit           False  1.262306e+09   \n",
       "1  c0i195b      worldnews           False  1.262313e+09   \n",
       "2  c0i1a0w    environment           False  1.262314e+09   \n",
       "\n",
       "                                           permalink  sentiment  score  \\\n",
       "0  https://old.reddit.com/r/AskReddit/comments/ak...     0.7998    1.0   \n",
       "1  https://old.reddit.com/r/worldnews/comments/ak...     0.4754    0.0   \n",
       "2  https://old.reddit.com/r/environment/comments/...     0.0242    1.0   \n",
       "\n",
       "  created_date  created_day  created_month  created_year created_time  \\\n",
       "0   2010-01-01            1              1          2010     00:34:07   \n",
       "1   2010-01-01            1              1          2010     02:30:18   \n",
       "2   2010-01-01            1              1          2010     02:54:40   \n",
       "\n",
       "   topic_number                        topic_name  \\\n",
       "0            -1  -1_climate_people_global_warming   \n",
       "1             0      0_people_just_climate_global   \n",
       "2             0      0_people_just_climate_global   \n",
       "\n",
       "                               topic_most_used_words  \\\n",
       "0  climate - people - global - warming - just - s...   \n",
       "1  people - just - climate - global - don - like ...   \n",
       "2  people - just - climate - global - don - like ...   \n",
       "\n",
       "                                     body_clean_full  \n",
       "0  should be \"San Diego Weatherman has an opinion...  \n",
       "1  Both Iggy and Harper would have marched us int...  \n",
       "2  A man who though a moderate Tory , has a mixed...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load comments\n",
    "df = pd.read_csv(\"data/comments_final.csv\", header=0, index_col=0)#\n",
    "\n",
    "# Sanity check\n",
    "if not df[df.isna().any(axis=1)].empty:\n",
    "    raise Exception(\"Sanity check failed! Empty rows detected!\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        object\n",
       "subreddit.name            object\n",
       "subreddit.nsfw              bool\n",
       "created_utc              float64\n",
       "permalink                 object\n",
       "sentiment                float64\n",
       "score                    float64\n",
       "created_date              object\n",
       "created_day                int64\n",
       "created_month              int64\n",
       "created_year               int64\n",
       "created_time              object\n",
       "topic_number               int64\n",
       "topic_name                object\n",
       "topic_most_used_words     object\n",
       "body_clean_full           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041570, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Not necessarily.  He could simply be [sympathetic to the environmentalism movement.]( .com/communities/greenhouse/post/ / /james-cameron-sees-avatar-as-environmental-warning/ )  Edit: Imagine a hypothetical scenario, if you will.    An environmentalist friend of Cameron calls him up for a chat:  Environmentalist: Hey James, you know that movie you've been thinking about doing; the one about the evil corporation who's destroying the planet for greed, and how the planet fights back in the end and wins?  James: Yeah?  Environmentalist: Well, I think that if you went ahead and did that, it could have a great effect on people right now.  We're trying to save the earth, and people just aren't really concerned enough for us to REALLY be able to make a difference.  We have the Copenhagen conference coming up at the end of  , and that will mark the beginning of the big push for real, meaningful change to save the environment.  The problem is that we just aren't quite sure that the American public is on board enough to make American assent to a global climate governing body politically feasible.  James: Yeah, I think you might be right...  It's time to do this.  Thanks bud, I'll ttyl.   Environmentalist: Take care, James.    Look at the movie.  Look at the message.  Look at the political climate.  Look at what's going on re: climate change and carbon trading.  Coincidence?  Probably not.    James might have even recognized the impact that his movie might have *on his own*.  Believe it or not, he's a pretty smart guy, so I hear.  \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sample text\n",
    "df.body_clean_full.iloc[21]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faulty rows of old preprocessed_comments file: \n",
    "\n",
    "368464 - 393215:    \"i38o4bg\tclimatechange\tFalse\t1649003948\t\"\n",
    "\n",
    "393217 - 425983:    \"0.0\t[AR IPCC Chapter : Understanding and Attribu...\tNaN\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HF Transformers Models\n",
    "\n",
    "Be aware: Models rather large, first time to run might take some downloading time (~500MB per model; saved in sth like \"C:\\Users\\Felix\\.cache\\huggingface\\hub\")\n",
    "\n",
    "All HF sentiment models: https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads&search=sentiment\n",
    "\n",
    "All HF emotion detection models: https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads&search=emotion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Model\n",
    "\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "\n",
    "ENCODING: 0 -> Negative; 1 -> Neutral; 2 -> Positive\n",
    "\n",
    "GPU: ~0.0105 sec/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\", device=device, batch_size=batch_size)\n",
    "model_name = \"sentiment\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate stance model\n",
    "\n",
    "https://huggingface.co/cardiffnlp/twitter-roberta-base-stance-climate\n",
    "\n",
    "Paper: https://aclanthology.org/S16-1003.pdf\n",
    "\n",
    "\"Climate Change is a Real Concern\" -> favor/against/none\n",
    "\n",
    "GPU: ~0.014 sec/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-stance-climate\", device=device, batch_size=batch_size)\n",
    "model_name = \"climate_stance\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate sentiment model\n",
    "\n",
    "https://huggingface.co/climatebert/distilroberta-base-climate-sentiment \n",
    "\n",
    "-> neutral, opportunity, risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"sentiment-analysis\", model=\"climatebert/distilroberta-base-climate-sentiment\", device=device, batch_size=batch_size)\n",
    "model_name = \"climate_sentiment\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large emotion model (28 states detected)\n",
    "\n",
    "Model: https://huggingface.co/arpanghoshal/EmoRoBERTa\n",
    "\n",
    "Labels detected: 'remorse', 'disappointment', 'sadness', 'gratitude', 'realization', 'disapproval', 'neutral', 'approval', 'embarrassment', 'caring', 'curiosity', 'confusion', 'annoyance', 'joy', 'optimism', 'relief', 'excitement', 'admiration', 'love', 'disgust', 'grief', 'amusement', 'anger', 'surprise', 'pride', 'nervousness', 'fear', 'desire'\n",
    "\n",
    "GPU: ~0,11 sec/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at arpanghoshal/EmoRoBERTa.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa', top_k=1, device=device, batch_size=batch_size) # top_k=None lists all labels\n",
    "model_name = \"emotion_large\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small emotion model (7 states)\n",
    "\n",
    "Model: https://huggingface.co/j-hartmann/emotion-english-distilroberta-base\n",
    "\n",
    "Labels detected: 'surprise', 'neutral', 'fear', 'anger', 'joy', 'disgust', 'sadness'\n",
    "\n",
    "GPU: ~0,011 sec/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=1, device=device, batch_size=batch_size) # top_k=None lists all labels\n",
    "model_name = \"emotion_small\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'favor', 'score': 0.9356362819671631}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prediction = model(\"Climate change is a big scam! Why is everyone so upset?!?!\")\n",
    "sample_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find labels included\n",
    "#labels = [i[\"label\"] for i in sample_prediction]\n",
    "#print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create backup of df\n",
    "#df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce text to character limit if there is one\n",
    "def reduce_text(text, max_length=np.inf):\n",
    "    if len(text) > max_length:\n",
    "        text = text[0:max_length]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment text reduced to 512 characters!\n"
     ]
    }
   ],
   "source": [
    "# Reduce texts if necessary\n",
    "df[\"body_clean_full\"] = df[\"body_clean_full\"].apply(reduce_text, args=(512, )) # e.g. for small sentiment model\n",
    "print(\"Comment text reduced to 512 characters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use subset\n",
    "df.sample(frac=1, random_state=42) # shuffle\n",
    "df = df.iloc[:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# CAUTION: THIS WILL RUN INFERENCE AND CAN THUS TAKE SOME TIME\n",
    "#df[\"label\"] = model(list(df[\"body_clean_full\"]))\n",
    "results = df.body_clean_full.iloc[:1000].map(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      should be \"San Diego Weatherman has an opinion...\n",
       "1      Both Iggy and Harper would have marched us int...\n",
       "2      A man who though a moderate Tory , has a mixed...\n",
       "3      Changing the oil *filter* every single time yo...\n",
       "4      ; We have no history - ours goes back only   y...\n",
       "                             ...                        \n",
       "995    take a look at the presidential voting record ...\n",
       "996    Sadly, I think she's spot on. As I posted in m...\n",
       "997    The Intergovernmental Panel on **Climate Chang...\n",
       "998    i was looking merely at a correlation between ...\n",
       "999    India has criticised the UN panel on climate c...\n",
       "Name: body_clean_full, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body_clean_full.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended inference on GPU\n",
    "# https://huggingface.co/docs/transformers/pipeline_tutorial#using-pipelines-on-a-dataset\n",
    "def load_iterator():\n",
    "    for i in df.body_clean_full.iloc[:1000]:\n",
    "        # DEBUGGING\n",
    "        # i = i.replace(\"\\\"\", \" \")\n",
    "        # i = i.replace(\"'\", \" \")\n",
    "        # print(i)\n",
    "        # print(\"\")\n",
    "        yield i\n",
    "\n",
    "results = []\n",
    "\n",
    "for out in model(load_iterator()):\n",
    "    results.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract (top) label\n",
    "results = [i[0][\"label\"] for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['favor', 'none'], dtype='<U5')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all top labels found\n",
    "np.unique(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "; We can't really predict what kind of technology we'll have in   years.  Ah, yes - the magical scientific solution to everything that might, hopefully get invented. The catch-all excuse to justify any behaviour now. Trouble is, it won't replace the species and biodiversity that has been lost. Nor will it prevent the death of millions as drought creeps across the planet.  ; Yeah, the road thing is an understatement - we'd have to rework our docks  Jesus. You've gone from moving roads to reworking docks only\n"
     ]
    }
   ],
   "source": [
    "# Get sample texts for certain label\n",
    "print(df[df.top_label == \"optimism\"].body_clean_full.iloc[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run prediction per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use subset\n",
    "# df = df.sample(frac=1, random_state=42) # shuffle\n",
    "# df = df.iloc[:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment text reduced to 512 characters!\n"
     ]
    }
   ],
   "source": [
    "# Reduce texts if necessary\n",
    "df[\"body_clean_full\"] = df[\"body_clean_full\"].apply(reduce_text, args=(512, )) # e.g. for small sentiment model\n",
    "print(\"Comment text reduced to 512 characters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020,\n",
       "       2021, 2022], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.created_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging\n",
    "# https://docs.python.org/3/howto/logging.html\n",
    "folder = f\"data/{model_name}_labels/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "logging.basicConfig(filename=f\"data/{model_name}_labels/{model_name}_logs.log\", level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(save_df, idx, to_csv=False):\n",
    "    idx = str(idx)\n",
    "    folder = f\"data/{model_name}_labels/\"\n",
    "    path = folder + f\"{model_name}_{idx}\"\n",
    "\n",
    "    if os.path.exists(path + \".pkl\"): \n",
    "        path = path + \"_\" + str(datetime.now())[-5:]\n",
    "        logging.info(str(datetime.now()) + f\" Warning: path already existed, will save as: {path}\")\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    try:\n",
    "        with open(path + \".pkl\", \"wb\") as f:\n",
    "            pickle.dump(save_df, f)\n",
    "        logging.info(str(datetime.now()) + f\" Year {idx} saved in {path}\")\n",
    "    except:\n",
    "        # Save to csv if failed\n",
    "        try:\n",
    "            logging.info(str(datetime.now()) + \" Pickling failed, will try to save as csv\")\n",
    "            save_df.to_csv(path + \"_BACKUP.csv\", index=False)\n",
    "        except:\n",
    "            logging.info(str(datetime.now()) + f\" ERROR: Failed to save year {idx}!\")\n",
    "            logging.info(str(sys.exc_info()))\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#save_file(df, 2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "# df.body_clean_full = [i.replace(\" \\\"\", \"\\\\\\\"\") for i in df.body_clean_full]\n",
    "# df.body_clean_full = [i.replace(\"'\", \" \") for i in df.body_clean_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "\n",
    "def executer(df_sample, year):\n",
    "    try:\n",
    "        logging.info(str(datetime.now()) + f\" Running inference for year {year}, with {df_sample.shape[0]} samples\")\n",
    "\n",
    "        # Run inference as recommended for GPU\n",
    "        # https://huggingface.co/docs/transformers/pipeline_tutorial#using-pipelines-on-a-dataset\n",
    "        def load_iterator():\n",
    "            for i in df_sample.body_clean_full: # FIXME DEBUGGING .iloc[83814:]\n",
    "                yield i[0:max_length]\n",
    "\n",
    "        labels = []\n",
    "        idx = 0\n",
    "        for idx, out in enumerate(model(load_iterator())): # Run inference and collect labels\n",
    "            last_idx = idx\n",
    "            labels.append(out)\n",
    "\n",
    "        #labels = model(list(df_sample[\"body_clean_full\"])) # OLD WAY TO RUN INFERENCE\n",
    "\n",
    "        #labels = [i[0][\"label\"] for i in labels]                                # FIXME for: emotion_small\n",
    "        labels = [i[\"label\"] for i in labels]                                   # FIXME for: climate_stance\n",
    "\n",
    "        df_save = pd.DataFrame({\"id\": df_sample.id, model_name: labels})\n",
    "        save_file(df_save, year)\n",
    "\n",
    "    except:\n",
    "        logging.info(str(datetime.now()) + f\" ERROR with year {year}: \\n\" + str(sys.exc_info()))\n",
    "        logging.info(str(datetime.now()) + f\" Last idx checked: {idx}, with id: {df_sample.iloc[idx,:].id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executer2(df_sample, year):\n",
    "    try:\n",
    "        logging.info(str(datetime.now()) + f\" Running inference for year {year}, with {df_sample.shape[0]} samples\")\n",
    "\n",
    "        # Run inference in basic way\n",
    "        labels = df.body_clean_full.map(model)\n",
    "        \n",
    "        labels = [i[0][\"label\"] for i in labels] # FIXME ADAPT PER MODEL\n",
    "\n",
    "        df_save = pd.DataFrame({\"id\": df_sample.id, model_name: labels})\n",
    "        save_file(df_save, year)\n",
    "\n",
    "    except:\n",
    "        logging.info(str(datetime.now()) + f\" ERROR with year {year}: \\n\" + str(sys.exc_info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "#executer(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME FIXME FIXME\n",
    "# TODO remove duplicates from already inferred data for emotion_small!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>subreddit.nsfw</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_time</th>\n",
       "      <th>topic_number</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_most_used_words</th>\n",
       "      <th>body_clean_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, subreddit.name, subreddit.nsfw, created_utc, permalink, sentiment, score, created_date, created_day, created_month, created_year, created_time, topic_number, topic_name, topic_most_used_words, body_clean_full]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df[df.body_clean_full.apply(len) > 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-13 12:03:58.409510 Running inference for climate_stance \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 13/13 [2:27:03<00:00, 678.74s/it] \n"
     ]
    }
   ],
   "source": [
    "# RUN INFERENCE ON ALL DATA\n",
    "\n",
    "years = df.created_year.unique()\n",
    "#years = [2015]#, 2021] # FIXME DEBUGGING\n",
    "years[years.sort()]\n",
    "\n",
    "logging.info(f\"Running inference for {model_name} \\n\")\n",
    "print(datetime.now(), f\"Running inference for {model_name} \\n\")\n",
    "\n",
    "for year in tqdm(years):\n",
    "    df_sample = df[df.created_year == year]\n",
    "    \n",
    "    executer(df_sample, year) # optimized way through iterator\n",
    "    #executer2(df_sample, year) # old way\n",
    "\n",
    "logging.info(f\"Inference finished for {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Climate change is the biggest threat and we have already acknowledged the danger that IS poses. Mentioning paris would have seemed redundant and it doesnt focus on the impending dangers to come. Yes paris was shitty but his point mentioning the climate change link was acknowledging that this issue with global terrorism and conflict has the potential to get much much worse unless it is made a central issue.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body_clean_full[df.created_year == 2015].iloc[83815]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove problem posing rows\n",
    "ids = [\"cx2fqug\", \"cnmkpqk\"]\n",
    "\n",
    "df = df[~df.id.isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That\\'s because so few people in the developed world are going to call themselves a \"climate change refugee.\"  \"So, why did you move?\"  Answers that may well mean you are climate change refugee, without having to formally acknowledge that fact to yourself or others:  \"We moved for better weather.\"  \"We moved to get away from all the snow.\"  \"We moved to lower our utility bills.  You wouldn\\'t believe how expensive water in [blank] has gotten!  Greedy government, gouging working people!\"  \"We moved because tho'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id == \"cnmkpqk\"].body_clean_full.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = df.created_year.unique()\n",
    "\n",
    "# start_time = time.localtime() # Save timestamps to show starting time and runtime\n",
    "# start_t = time.time()\n",
    "# print(datetime.now(), \"Inference started\")\n",
    "\n",
    "# # Run inference in parallel\n",
    "# p = mp.Pool() # without argument uses: os.cpu_count(), i.e. max number of threads\n",
    "# p.map_async(executer, years)\n",
    "# p.close()\n",
    "# p.join()\n",
    "\n",
    "# end_t = time.time()\n",
    "# print(datetime.now(), \"Computation time (Min.):\", (end_t-start_t)/60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file\n",
    "with open(f\"data/{model_name}_labels/{model_name}_2021.pkl\", \"rb\") as f:\n",
    "    labels_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1069123</th>\n",
       "      <td>hpsc48q</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052862</th>\n",
       "      <td>hiizdql</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032030</th>\n",
       "      <td>haa9dbm</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981644</th>\n",
       "      <td>gnridwg</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990338</th>\n",
       "      <td>gs9y8eh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996821</th>\n",
       "      <td>gvwmgp9</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027574</th>\n",
       "      <td>h8plyab</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035834</th>\n",
       "      <td>hbrxh49</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008584</th>\n",
       "      <td>h2rbqc6</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021415</th>\n",
       "      <td>h6zogcb</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id emotion_small\n",
       "1069123  hpsc48q       neutral\n",
       "1052862  hiizdql       neutral\n",
       "1032030  haa9dbm       disgust\n",
       "981644   gnridwg           joy\n",
       "990338   gs9y8eh       neutral\n",
       "...          ...           ...\n",
       "996821   gvwmgp9       neutral\n",
       "1027574  h8plyab           joy\n",
       "1035834  hbrxh49       neutral\n",
       "1008584  h2rbqc6       neutral\n",
       "1021415  h6zogcb       neutral\n",
       "\n",
       "[81 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join labels to full results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
