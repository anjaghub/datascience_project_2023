{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Climate Change - Modeling & Evaluation\n",
    "Supervision: Prof. Dr. Jan Fabian Ehmke\n",
    "\n",
    "Group members: Britz Luis, Huber Anja, Krause Felix Elias, Preda Yvonne-Nadine\n",
    "\n",
    "Time: Summer term 2023 \n",
    "\n",
    "Data: https://www.kaggle.com/datasets/pavellexyr/the-reddit-climate-change-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Topic detection\n",
    "\n",
    "# LDA\n",
    "# https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "# http://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "\n",
    "# BERTopic\n",
    "# https://maartengr.github.io/BERTopic/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "# Preparing environment\n",
    "#%pip install bertopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_90578/3432851145.py:2: DtypeWarning: Columns (0,1,2,4,7,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clean_comments = pd.read_csv(\"data/preprocessed_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "clean_comments = pd.read_csv(\"data/preprocessed_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comments[\"created_year\"] = pd.to_datetime(clean_comments[\"created_year\"],format=\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>subreddit.nsfw</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_time</th>\n",
       "      <th>body_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i79uz1c</td>\n",
       "      <td>oddlyterrifying</td>\n",
       "      <td>False</td>\n",
       "      <td>1.651658e+09</td>\n",
       "      <td>https://old.reddit.com/r/oddlyterrifying/comme...</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>09:58:26</td>\n",
       "      <td>Oh shit there's a new one out? Last one k watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hz51unj</td>\n",
       "      <td>technews</td>\n",
       "      <td>False</td>\n",
       "      <td>1.646280e+09</td>\n",
       "      <td>https://old.reddit.com/r/technews/comments/t53...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>03:54:08</td>\n",
       "      <td>Weâ€™re never going to reopen those wells, its e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i3ic64d</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>1.649177e+09</td>\n",
       "      <td>https://old.reddit.com/r/worldnews/comments/tw...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>16:36:35</td>\n",
       "      <td>Climate Change is the Great Filter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3tlo2</td>\n",
       "      <td>ontario</td>\n",
       "      <td>False</td>\n",
       "      <td>1.655760e+09</td>\n",
       "      <td>https://old.reddit.com/r/ontario/comments/vglj...</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>21:16:31</td>\n",
       "      <td>Climate change also means greater crop yields ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iebulu4</td>\n",
       "      <td>news</td>\n",
       "      <td>False</td>\n",
       "      <td>1.656603e+09</td>\n",
       "      <td>https://old.reddit.com/r/news/comments/vo98pd/...</td>\n",
       "      <td>-0.6115</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>15:26:18</td>\n",
       "      <td>The decline into total destruction by climate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   subreddit.name subreddit.nsfw   created_utc   \n",
       "0  i79uz1c  oddlyterrifying          False  1.651658e+09  \\\n",
       "1  hz51unj         technews          False  1.646280e+09   \n",
       "2  i3ic64d        worldnews          False  1.649177e+09   \n",
       "3  id3tlo2          ontario          False  1.655760e+09   \n",
       "4  iebulu4             news          False  1.656603e+09   \n",
       "\n",
       "                                           permalink  sentiment  score   \n",
       "0  https://old.reddit.com/r/oddlyterrifying/comme...    -0.5574    3.0  \\\n",
       "1  https://old.reddit.com/r/technews/comments/t53...     0.4588    1.0   \n",
       "2  https://old.reddit.com/r/worldnews/comments/tw...     0.6249    1.0   \n",
       "3  https://old.reddit.com/r/ontario/comments/vglj...     0.2960    0.0   \n",
       "4  https://old.reddit.com/r/news/comments/vo98pd/...    -0.6115   12.0   \n",
       "\n",
       "  created_date  created_day  created_month created_year created_time   \n",
       "0   2022-05-04          4.0            5.0   2022-01-01     09:58:26  \\\n",
       "1   2022-03-03          3.0            3.0   2022-01-01     03:54:08   \n",
       "2   2022-04-05          5.0            4.0   2022-01-01     16:36:35   \n",
       "3   2022-06-20         20.0            6.0   2022-01-01     21:16:31   \n",
       "4   2022-06-30         30.0            6.0   2022-01-01     15:26:18   \n",
       "\n",
       "                                          body_clean  \n",
       "0  Oh shit there's a new one out? Last one k watc...  \n",
       "1  Weâ€™re never going to reopen those wells, its e...  \n",
       "2                Climate Change is the Great Filter.  \n",
       "3  Climate change also means greater crop yields ...  \n",
       "4  The decline into total destruction by climate ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Topic Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create a subsets for every year\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m year_groups \u001b[39m=\u001b[39m clean_comments\u001b[39m.\u001b[39mgroupby(clean_comments[\u001b[39m'\u001b[39;49m\u001b[39mcreated_year\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39myear)\n\u001b[1;32m      4\u001b[0m year_dfs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mcomments_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(year): group \u001b[39mfor\u001b[39;00m year, group \u001b[39min\u001b[39;00m year_groups}\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m year, group \u001b[39min\u001b[39;00m year_groups:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m is_period_dtype(data\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 580\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Create a subsets for every year\n",
    "year_groups = clean_comments.groupby(clean_comments['created_year'].dt.year)\n",
    "\n",
    "year_dfs = {'comments_{}'.format(year): group for year, group in year_groups}\n",
    "\n",
    "for year, group in year_groups:\n",
    "    year_dfs[year] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one array of all titles, to feed it into BERT\n",
    "docs = subset_comments.body_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [04:10<00:00,  2.00it/s]\n",
      "2023-05-03 10:44:09,965 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-03 10:44:40,232 - BERTopic - Reduced dimensionality\n",
      "2023-05-03 10:44:40,674 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-03 10:44:45,574 - BERTopic - Reduced number of topics from 106 to 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>8554</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1544</td>\n",
       "      <td>0_science_people_gt_don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1154</td>\n",
       "      <td>1_weather_warming_global_snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "      <td>2_temperature_atmosphere_water_vapor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>315</td>\n",
       "      <td>3_obama_rudd_labor_party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>68_grassroots_poptart_article_typety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>69_causation_correlation_does_equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>70_economics_economists_nafta_maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>71_ica_water_peru_aquifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>72_exxonmobil_exxon_million_groups</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                  Name\n",
       "0      -1   8554              -1_people_gt_global_just\n",
       "1       0   1544               0_science_people_gt_don\n",
       "2       1   1154         1_weather_warming_global_snow\n",
       "3       2    505  2_temperature_atmosphere_water_vapor\n",
       "4       3    315              3_obama_rudd_labor_party\n",
       "..    ...    ...                                   ...\n",
       "69     68     16  68_grassroots_poptart_article_typety\n",
       "70     69     16   69_causation_correlation_does_equal\n",
       "71     70     16   70_economics_economists_nafta_maths\n",
       "72     71     15             71_ica_water_peru_aquifer\n",
       "73     72     15    72_exxonmobil_exxon_million_groups\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT stepwise\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "  calculate_probabilities=False,      # Raises speed\n",
    "  min_topic_size = 300,               # Reduces number of topics\n",
    "  nr_topics=\"auto\",                    # Reduces number of topics\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('science', 0.01219470217097759),\n",
       " ('people', 0.010584660869951001),\n",
       " ('gt', 0.009517132731414605),\n",
       " ('don', 0.0086000351186167),\n",
       " ('scientific', 0.008597060961067942),\n",
       " ('global', 0.00822324026848448),\n",
       " ('think', 0.00787297838775973),\n",
       " ('scientists', 0.007625308000465114),\n",
       " ('evolution', 0.007521849591286694),\n",
       " ('warming', 0.007371242329106124)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get specific topic\n",
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store topic info in dataframe\n",
    "doc_info = topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Industrial output --&amp;gt; Increased atmospheric...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "      <td>people - gt - global - just - science - don - ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is true but only because Australia lacks ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "      <td>people - gt - global - just - science - don - ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please, explain to us the whole concept.\\n\\nNe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "      <td>people - gt - global - just - science - don - ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It hasn't been \"d\" some political types prefer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_weather_warming_global_snow</td>\n",
       "      <td>weather - warming - global - snow - ice - temp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;gt; It's called \" \" or as the right wing has ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_weather_warming_global_snow</td>\n",
       "      <td>weather - warming - global - snow - ice - temp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic   \n",
       "0  Industrial output --&gt; Increased atmospheric...     -1  \\\n",
       "1  This is true but only because Australia lacks ...     -1   \n",
       "2  Please, explain to us the whole concept.\\n\\nNe...     -1   \n",
       "3  It hasn't been \"d\" some political types prefer...      1   \n",
       "4  &gt; It's called \" \" or as the right wing has ...      1   \n",
       "\n",
       "                            Name   \n",
       "0       -1_people_gt_global_just  \\\n",
       "1       -1_people_gt_global_just   \n",
       "2       -1_people_gt_global_just   \n",
       "3  1_weather_warming_global_snow   \n",
       "4  1_weather_warming_global_snow   \n",
       "\n",
       "                                         Top_n_words  Probability   \n",
       "0  people - gt - global - just - science - don - ...          0.0  \\\n",
       "1  people - gt - global - just - science - don - ...          0.0   \n",
       "2  people - gt - global - just - science - don - ...          0.0   \n",
       "3  weather - warming - global - snow - ice - temp...          1.0   \n",
       "4  weather - warming - global - snow - ice - temp...          1.0   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out document information\n",
    "doc_info.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
