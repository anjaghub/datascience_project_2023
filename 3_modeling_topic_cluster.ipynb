{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Climate Change - Modeling & Evaluation\n",
    "Supervision: Prof. Dr. Jan Fabian Ehmke\n",
    "\n",
    "Group members: Britz Luis, Huber Anja, Krause Felix Elias, Preda Yvonne-Nadine\n",
    "\n",
    "Time: Summer term 2023 \n",
    "\n",
    "Data: https://www.kaggle.com/datasets/pavellexyr/the-reddit-climate-change-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Topic detection\n",
    "\n",
    "# LDA\n",
    "# https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "# http://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "\n",
    "# BERTopic\n",
    "# https://maartengr.github.io/BERTopic/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Using cached bertopic-0.14.1-py2.py3-none-any.whl (120 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/homebrew/lib/python3.10/site-packages (from bertopic) (1.24.3)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Using cached hdbscan-0.8.29-cp310-cp310-macosx_10_9_universal2.whl\n",
      "Collecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Using cached umap_learn-0.5.3-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/homebrew/lib/python3.10/site-packages (from bertopic) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/homebrew/lib/python3.10/site-packages (from bertopic) (1.2.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /opt/homebrew/lib/python3.10/site-packages (from bertopic) (4.65.0)\n",
      "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting plotly>=4.7.0 (from bertopic)\n",
      "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cython>=0.27 (from hdbscan>=0.8.29->bertopic)\n",
      "  Using cached Cython-0.29.34-py2.py3-none-any.whl (988 kB)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/homebrew/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anja/Library/Python/3.10/lib/python/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3)\n",
      "Collecting tenacity>=6.2.0 (from plotly>=4.7.0->bertopic)\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in /Users/anja/Library/Python/3.10/lib/python/site-packages (from plotly>=4.7.0->bertopic) (23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached torch-2.0.0-cp310-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "Collecting torchvision (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached torchvision-0.15.1-cp310-cp310-macosx_11_0_arm64.whl (1.4 MB)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Collecting numba>=0.49 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading numba-0.57.0-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Using cached pynndescent-0.5.10-py3-none-any.whl\n",
      "Collecting filelock (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting fsspec (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "Collecting requests (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1 (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached PyYAML-6.0-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0 (from numba>=0.49->umap-learn>=0.5.0->bertopic)\n",
      "  Downloading llvmlite-0.40.0-cp310-cp310-macosx_11_0_arm64.whl (28.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.1/28.1 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/anja/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Collecting networkx (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting jinja2 (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2023.3.23)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl (3.9 MB)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.10/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.5.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading MarkupSafe-2.1.2-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-macosx_11_0_arm64.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.0/123.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5 (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tokenizers, sentencepiece, mpmath, urllib3, typing-extensions, tenacity, sympy, pyyaml, networkx, MarkupSafe, llvmlite, idna, fsspec, filelock, cython, charset-normalizer, certifi, requests, plotly, numba, jinja2, torch, pynndescent, huggingface-hub, hdbscan, umap-learn, transformers, torchvision, sentence-transformers, bertopic\n",
      "Successfully installed MarkupSafe-2.1.2 bertopic-0.14.1 certifi-2022.12.7 charset-normalizer-3.1.0 cython-0.29.34 filelock-3.12.0 fsspec-2023.4.0 hdbscan-0.8.29 huggingface-hub-0.14.1 idna-3.4 jinja2-3.1.2 llvmlite-0.40.0 mpmath-1.3.0 networkx-3.1 numba-0.57.0 plotly-5.14.1 pynndescent-0.5.10 pyyaml-6.0 requests-2.29.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.11.1 tenacity-8.2.2 tokenizers-0.13.3 torch-2.0.0 torchvision-0.15.1 transformers-4.28.1 typing-extensions-4.5.0 umap-learn-0.5.3 urllib3-1.26.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "# Preparing environment\n",
    "%pip install bertopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_1980/2118955341.py:3: DtypeWarning: Columns (0,1,2,3,4,5,6,7,10,11,12,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clean_comments = pd.read_csv(\"data/preprocessed_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "clean_posts = pd.read_csv(\"data/preprocessed_posts.csv\")\n",
    "clean_comments = pd.read_csv(\"data/preprocessed_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160540"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count NAs in date column\n",
    "clean_comments[\"created_date\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs, should be done in preprocessing file, delete it here!\n",
    "clean_comments = clean_comments.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit.id</th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>subreddit.nsfw</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>body_clean</th>\n",
       "      <th>language</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>imlddn9</td>\n",
       "      <td>2qh3l</td>\n",
       "      <td>news</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990368</td>\n",
       "      <td>https://old.reddit.com/r/news/comments/x2cszk/...</td>\n",
       "      <td>Yeah but what the above commenter is saying is...</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yeah but what the above commenter is saying is...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:59:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>imldbeh</td>\n",
       "      <td>2qn7b</td>\n",
       "      <td>ohio</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990340</td>\n",
       "      <td>https://old.reddit.com/r/Ohio/comments/x2awnp/...</td>\n",
       "      <td>Any comparison of efficiency between solar and...</td>\n",
       "      <td>-0.9877</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Any comparison of efficiency between solar and...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>imldado</td>\n",
       "      <td>2qhma</td>\n",
       "      <td>newzealand</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990327</td>\n",
       "      <td>https://old.reddit.com/r/newzealand/comments/x...</td>\n",
       "      <td>I'm honestly waiting for climate change and th...</td>\n",
       "      <td>-0.1143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm honestly waiting for   and the impacts of ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:58:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>imld6cb</td>\n",
       "      <td>2qi09</td>\n",
       "      <td>sacramento</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990278</td>\n",
       "      <td>https://old.reddit.com/r/Sacramento/comments/x...</td>\n",
       "      <td>Not just Sacramento. It's actually happening a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Not just Sacramento. It's actually happening a...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:57:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>imld0kj</td>\n",
       "      <td>2qh1i</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990206</td>\n",
       "      <td>https://old.reddit.com/r/AskReddit/comments/x2...</td>\n",
       "      <td>I think climate change tends to get some peopl...</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I think   tends to get some people riled up. \\...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:56:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comment</td>\n",
       "      <td>imlctri</td>\n",
       "      <td>3l2gt</td>\n",
       "      <td>walkaway</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990120</td>\n",
       "      <td>https://old.reddit.com/r/walkaway/comments/x2m...</td>\n",
       "      <td>Naaa how could anyone be mad at a face like th...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Naaa how could anyone be mad at a face like th...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:55:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comment</td>\n",
       "      <td>imlctc0</td>\n",
       "      <td>2vvve</td>\n",
       "      <td>pastors</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990114</td>\n",
       "      <td>https://old.reddit.com/r/pastors/comments/x2il...</td>\n",
       "      <td>Can i suggest maybe honing in on LGBTQ?\\n\\nIt'...</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Can i suggest maybe honing in on LGBTQ?\\n\\nIt'...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:55:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comment</td>\n",
       "      <td>imlcpab</td>\n",
       "      <td>2qh1i</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990065</td>\n",
       "      <td>https://old.reddit.com/r/AskReddit/comments/x2...</td>\n",
       "      <td>They need to change laws so it's more worth se...</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>2.0</td>\n",
       "      <td>They need to  laws so it's more worth selling ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:54:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comment</td>\n",
       "      <td>imlcm07</td>\n",
       "      <td>2sa17</td>\n",
       "      <td>hudsonvalley</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990023</td>\n",
       "      <td>https://old.reddit.com/r/hudsonvalley/comments...</td>\n",
       "      <td>Just thought I would share the climatological ...</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Just thought I would share the climatological ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comment</td>\n",
       "      <td>imlcln1</td>\n",
       "      <td>2t7no</td>\n",
       "      <td>futurology</td>\n",
       "      <td>False</td>\n",
       "      <td>1661990019</td>\n",
       "      <td>https://old.reddit.com/r/Futurology/comments/x...</td>\n",
       "      <td>Blaming environmentalists for the failure of n...</td>\n",
       "      <td>0.3094</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Blaming environmentalists for the failure of n...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23:53:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type       id subreddit.id subreddit.name subreddit.nsfw created_utc   \n",
       "0  comment  imlddn9        2qh3l           news          False  1661990368  \\\n",
       "1  comment  imldbeh        2qn7b           ohio          False  1661990340   \n",
       "2  comment  imldado        2qhma     newzealand          False  1661990327   \n",
       "3  comment  imld6cb        2qi09     sacramento          False  1661990278   \n",
       "4  comment  imld0kj        2qh1i      askreddit          False  1661990206   \n",
       "5  comment  imlctri        3l2gt       walkaway          False  1661990120   \n",
       "6  comment  imlctc0        2vvve        pastors          False  1661990114   \n",
       "7  comment  imlcpab        2qh1i      askreddit          False  1661990065   \n",
       "8  comment  imlcm07        2sa17   hudsonvalley          False  1661990023   \n",
       "9  comment  imlcln1        2t7no     futurology          False  1661990019   \n",
       "\n",
       "                                           permalink   \n",
       "0  https://old.reddit.com/r/news/comments/x2cszk/...  \\\n",
       "1  https://old.reddit.com/r/Ohio/comments/x2awnp/...   \n",
       "2  https://old.reddit.com/r/newzealand/comments/x...   \n",
       "3  https://old.reddit.com/r/Sacramento/comments/x...   \n",
       "4  https://old.reddit.com/r/AskReddit/comments/x2...   \n",
       "5  https://old.reddit.com/r/walkaway/comments/x2m...   \n",
       "6  https://old.reddit.com/r/pastors/comments/x2il...   \n",
       "7  https://old.reddit.com/r/AskReddit/comments/x2...   \n",
       "8  https://old.reddit.com/r/hudsonvalley/comments...   \n",
       "9  https://old.reddit.com/r/Futurology/comments/x...   \n",
       "\n",
       "                                                body  sentiment  score   \n",
       "0  Yeah but what the above commenter is saying is...     0.5719    2.0  \\\n",
       "1  Any comparison of efficiency between solar and...    -0.9877    2.0   \n",
       "2  I'm honestly waiting for climate change and th...    -0.1143    1.0   \n",
       "3  Not just Sacramento. It's actually happening a...     0.0000    4.0   \n",
       "4  I think climate change tends to get some peopl...     0.6634    1.0   \n",
       "5  Naaa how could anyone be mad at a face like th...     0.2500    1.0   \n",
       "6  Can i suggest maybe honing in on LGBTQ?\\n\\nIt'...     0.9779    2.0   \n",
       "7  They need to change laws so it's more worth se...     0.4690    2.0   \n",
       "8  Just thought I would share the climatological ...     0.7367    3.0   \n",
       "9  Blaming environmentalists for the failure of n...     0.3094    4.0   \n",
       "\n",
       "                                          body_clean language created_date   \n",
       "0  Yeah but what the above commenter is saying is...       en   2022-08-31  \\\n",
       "1  Any comparison of efficiency between solar and...       en   2022-08-31   \n",
       "2  I'm honestly waiting for   and the impacts of ...       en   2022-08-31   \n",
       "3  Not just Sacramento. It's actually happening a...       en   2022-08-31   \n",
       "4  I think   tends to get some people riled up. \\...       en   2022-08-31   \n",
       "5  Naaa how could anyone be mad at a face like th...       en   2022-08-31   \n",
       "6  Can i suggest maybe honing in on LGBTQ?\\n\\nIt'...       en   2022-08-31   \n",
       "7  They need to  laws so it's more worth selling ...       en   2022-08-31   \n",
       "8  Just thought I would share the climatological ...       en   2022-08-31   \n",
       "9  Blaming environmentalists for the failure of n...       en   2022-08-31   \n",
       "\n",
       "   created_day  created_month  created_year created_time  \n",
       "0         31.0            8.0        2022.0     23:59:28  \n",
       "1         31.0            8.0        2022.0     23:59:00  \n",
       "2         31.0            8.0        2022.0     23:58:47  \n",
       "3         31.0            8.0        2022.0     23:57:58  \n",
       "4         31.0            8.0        2022.0     23:56:46  \n",
       "5         31.0            8.0        2022.0     23:55:20  \n",
       "6         31.0            8.0        2022.0     23:55:14  \n",
       "7         31.0            8.0        2022.0     23:54:25  \n",
       "8         31.0            8.0        2022.0     23:53:43  \n",
       "9         31.0            8.0        2022.0     23:53:39  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataset\n",
    "clean_comments.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Topic Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of posts because otherwise it's to much data\n",
    "subset_comments = clean_comments[(clean_comments['created_year'] == 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one array of all titles, to feed it into BERT\n",
    "docs = subset_comments.body_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 500/500 [04:10<00:00,  2.00it/s]\n",
      "2023-05-03 10:44:09,965 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-03 10:44:40,232 - BERTopic - Reduced dimensionality\n",
      "2023-05-03 10:44:40,674 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-03 10:44:45,574 - BERTopic - Reduced number of topics from 106 to 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>8554</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1544</td>\n",
       "      <td>0_science_people_gt_don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1154</td>\n",
       "      <td>1_weather_warming_global_snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>505</td>\n",
       "      <td>2_temperature_atmosphere_water_vapor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>315</td>\n",
       "      <td>3_obama_rudd_labor_party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>68_grassroots_poptart_article_typety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>16</td>\n",
       "      <td>69_causation_correlation_does_equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>70_economics_economists_nafta_maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>71_ica_water_peru_aquifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>72_exxonmobil_exxon_million_groups</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                  Name\n",
       "0      -1   8554              -1_people_gt_global_just\n",
       "1       0   1544               0_science_people_gt_don\n",
       "2       1   1154         1_weather_warming_global_snow\n",
       "3       2    505  2_temperature_atmosphere_water_vapor\n",
       "4       3    315              3_obama_rudd_labor_party\n",
       "..    ...    ...                                   ...\n",
       "69     68     16  68_grassroots_poptart_article_typety\n",
       "70     69     16   69_causation_correlation_does_equal\n",
       "71     70     16   70_economics_economists_nafta_maths\n",
       "72     71     15             71_ica_water_peru_aquifer\n",
       "73     72     15    72_exxonmobil_exxon_million_groups\n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT stepwise\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "  calculate_probabilities=False,      # Raises speed\n",
    "  min_topic_size = 300,               # Reduces number of topics\n",
    "  nr_topics=\"auto\",                    # Reduces number of topics\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('science', 0.01219470217097759),\n",
       " ('people', 0.010584660869951001),\n",
       " ('gt', 0.009517132731414605),\n",
       " ('don', 0.0086000351186167),\n",
       " ('scientific', 0.008597060961067942),\n",
       " ('global', 0.00822324026848448),\n",
       " ('think', 0.00787297838775973),\n",
       " ('scientists', 0.007625308000465114),\n",
       " ('evolution', 0.007521849591286694),\n",
       " ('warming', 0.007371242329106124)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get specific topic\n",
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store topic info in dataframe\n",
    "doc_info = topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Industrial output --&amp;gt; Increased atmospheric...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "      <td>people - gt - global - just - science - don - ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is true but only because Australia lacks ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "      <td>people - gt - global - just - science - don - ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please, explain to us the whole concept.\\n\\nNe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_gt_global_just</td>\n",
       "      <td>people - gt - global - just - science - don - ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It hasn't been \"d\" some political types prefer...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_weather_warming_global_snow</td>\n",
       "      <td>weather - warming - global - snow - ice - temp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;gt; It's called \" \" or as the right wing has ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_weather_warming_global_snow</td>\n",
       "      <td>weather - warming - global - snow - ice - temp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic   \n",
       "0  Industrial output --&gt; Increased atmospheric...     -1  \\\n",
       "1  This is true but only because Australia lacks ...     -1   \n",
       "2  Please, explain to us the whole concept.\\n\\nNe...     -1   \n",
       "3  It hasn't been \"d\" some political types prefer...      1   \n",
       "4  &gt; It's called \" \" or as the right wing has ...      1   \n",
       "\n",
       "                            Name   \n",
       "0       -1_people_gt_global_just  \\\n",
       "1       -1_people_gt_global_just   \n",
       "2       -1_people_gt_global_just   \n",
       "3  1_weather_warming_global_snow   \n",
       "4  1_weather_warming_global_snow   \n",
       "\n",
       "                                         Top_n_words  Probability   \n",
       "0  people - gt - global - just - science - don - ...          0.0  \\\n",
       "1  people - gt - global - just - science - don - ...          0.0   \n",
       "2  people - gt - global - just - science - don - ...          0.0   \n",
       "3  weather - warming - global - snow - ice - temp...          1.0   \n",
       "4  weather - warming - global - snow - ice - temp...          1.0   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out document information\n",
    "doc_info.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
