{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Climate Change - Modeling & Evaluation\n",
    "Supervision: Prof. Dr. Jan Fabian Ehmke\n",
    "\n",
    "Group members: Britz Luis, Huber Anja, Krause Felix Elias, Preda Yvonne-Nadine\n",
    "\n",
    "Time: Summer term 2023 \n",
    "\n",
    "Data: https://www.kaggle.com/datasets/pavellexyr/the-reddit-climate-change-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Topic detection information material\n",
    "\n",
    "# LDA\n",
    "# https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "# http://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "\n",
    "# BERTopic\n",
    "# https://maartengr.github.io/BERTopic/index.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Environment and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/homebrew/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "# Preparing environment\n",
    "#%pip install bertopic\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/kbz524cd32j80_2tm_hwnr780000gn/T/ipykernel_96121/3432851145.py:2: DtypeWarning: Columns (0,1,2,4,7,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clean_comments = pd.read_csv(\"data/preprocessed_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "clean_comments = pd.read_csv(\"data/preprocessed_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na rows are again created and should be removed\n",
    "clean_comments = clean_comments.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp because import creates float variables\n",
    "clean_comments[\"created_year\"] = pd.to_datetime(clean_comments[\"created_date\"]).dt.strftime('%Y')\n",
    "clean_comments[\"created_month\"] = pd.to_datetime(clean_comments[\"created_date\"]).dt.strftime('%m')\n",
    "clean_comments[\"created_day\"] = pd.to_datetime(clean_comments[\"created_date\"]).dt.strftime('%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove climate change as word\n",
    "clean_comments[\"body_clean\"] = clean_comments[\"body_clean\"].apply(lambda x: re.sub(\"climate change\", \"\", x, flags=re.IGNORECASE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Topic Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of dataframe for every year\n",
    "year_groups = clean_comments.groupby(clean_comments['created_year'])\n",
    "\n",
    "year_dfs = {'comments_{}'.format(year): group for year, group in year_groups}\n",
    "\n",
    "for year, group in year_groups:\n",
    "    year_dfs[year] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate text documents per year\n",
    "docs_2010 = year_dfs[\"comments_2010\"][\"body_clean\"].values\n",
    "docs_2011 = year_dfs[\"comments_2011\"][\"body_clean\"].values\n",
    "docs_2012 = year_dfs[\"comments_2012\"][\"body_clean\"].values\n",
    "docs_2013 = year_dfs[\"comments_2013\"][\"body_clean\"].values\n",
    "docs_2014 = year_dfs[\"comments_2014\"][\"body_clean\"].values\n",
    "docs_2015 = year_dfs[\"comments_2015\"][\"body_clean\"].values\n",
    "docs_2016 = year_dfs[\"comments_2016\"][\"body_clean\"].values\n",
    "docs_2017 = year_dfs[\"comments_2017\"][\"body_clean\"].values\n",
    "docs_2018 = year_dfs[\"comments_2018\"][\"body_clean\"].values\n",
    "docs_2019 = year_dfs[\"comments_2019\"][\"body_clean\"].values\n",
    "docs_2020 = year_dfs[\"comments_2020\"][\"body_clean\"].values\n",
    "docs_2021 = year_dfs[\"comments_2021\"][\"body_clean\"].values\n",
    "docs_2022 = year_dfs[\"comments_2022\"][\"body_clean\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables to train model separately per year\n",
    "topic_models = {}\n",
    "doc_tuples = [(2010, docs_2010), (2011, docs_2011), (2012, docs_2012), (2013, docs_2013), (2014, docs_2014), (2015, docs_2015), (2016, docs_2016), (2017, docs_2017), (2018, docs_2018), (2019, docs_2019), (2020, docs_2020), (2021, docs_2021), (2022, docs_2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841885499fc34ea98d2090ea31829f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 13:25:33,175 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 13:25:37,715 - BERTopic - Reduced dimensionality\n",
      "2023-05-08 13:25:38,136 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 13:25:41,987 - BERTopic - Reduced number of topics from 103 to 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3068bcefd240f6a2283bde6eecfa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 13:33:01,008 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 13:33:07,232 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 13:33:08,508 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 13:33:14,824 - BERTopic - Reduced number of topics from 154 to 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9fe31beed641d9be7747608217b38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 13:44:18,296 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 13:44:32,605 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 13:44:34,460 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 13:44:43,864 - BERTopic - Reduced number of topics from 222 to 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529e5894b4624f80bb058efa921424bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4979 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:04:49,893 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 14:05:53,119 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:06:01,660 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 14:06:15,340 - BERTopic - Reduced number of topics from 235 to 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9814cf261ddf4ce88b65bc2e22b99851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:32:22,067 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 14:33:06,424 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:33:11,750 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 14:33:34,329 - BERTopic - Reduced number of topics from 379 to 289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920c348a7b5144ffb735273ef5382a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:57:36,753 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 14:58:04,258 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:58:07,949 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 14:58:29,773 - BERTopic - Reduced number of topics from 424 to 327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89e06a0f36f40789c24a9b001178925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 15:22:11,716 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 15:22:37,874 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 15:22:41,520 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 15:23:02,772 - BERTopic - Reduced number of topics from 410 to 333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7deed2b9d094dd787c630412ba774d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 15:46:03,354 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 15:46:29,298 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 15:46:32,944 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 15:46:51,912 - BERTopic - Reduced number of topics from 412 to 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c940537fd14c9db9d9820f00318991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 16:40:20,153 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 16:40:43,463 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 16:40:46,815 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 16:48:52,229 - BERTopic - Reduced number of topics from 410 to 184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59d5d46cfd84b72aa340f500ea17fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:28:30,598 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 19:28:55,843 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:28:59,457 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 19:29:19,090 - BERTopic - Reduced number of topics from 422 to 315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25bd36a4f914063a514016b40e7d035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:51:30,335 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 19:51:56,266 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 19:52:00,060 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 19:52:19,642 - BERTopic - Reduced number of topics from 429 to 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7a142b67b14394bea49964d51902a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 20:13:49,784 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 20:14:15,430 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 20:14:19,076 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 20:14:37,541 - BERTopic - Reduced number of topics from 428 to 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eba1cded044783827b5d926061fea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3098 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 21:18:19,875 - BERTopic - Transformed documents to Embeddings\n",
      "2023-05-08 21:18:45,430 - BERTopic - Reduced dimensionality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 21:18:49,101 - BERTopic - Clustered reduced embeddings\n",
      "2023-05-08 21:19:07,546 - BERTopic - Reduced number of topics from 430 to 104\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for year, year_docs in doc_tuples:\n",
    "\n",
    "  # BERT stepwise\n",
    "  # Step 1 - Extract embeddings\n",
    "  embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "  # Step 2 - Reduce dimensionality\n",
    "  umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "  # Step 3 - Cluster reduced embeddings\n",
    "  hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "  # Step 4 - Tokenize topics\n",
    "  vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "  # Step 5 - Create topic representation\n",
    "  ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "  # All steps together\n",
    "  topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,    # Step 1 - Extract embeddings\n",
    "    umap_model=umap_model,              # Step 2 - Reduce dimensionality\n",
    "    hdbscan_model=hdbscan_model,        # Step 3 - Cluster reduced embeddings\n",
    "    vectorizer_model=vectorizer_model,  # Step 4 - Tokenize topics\n",
    "    ctfidf_model=ctfidf_model,          # Step 5 - Extract topic words\n",
    "    calculate_probabilities=False,      # Raises speed\n",
    "    min_topic_size = 300,               # Reduces number of topics\n",
    "    nr_topics=\"auto\",                    # Reduces number of topics\n",
    "    verbose=True\n",
    "  )\n",
    "\n",
    "  topics, probs = topic_model.fit_transform(year_docs)\n",
    "  topic_models[f\"model_{year}\"] = topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>49437</td>\n",
       "      <td>-1_people_just_like_climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38326</td>\n",
       "      <td>0_people_like_just_don</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1190</td>\n",
       "      <td>1_protest_protests_protesting_protesters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>704</td>\n",
       "      <td>2_god_church_religion_bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>593</td>\n",
       "      <td>3_plastic_recycling_plastics_straws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>577</td>\n",
       "      <td>4_trans_gender_women_men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>464</td>\n",
       "      <td>5_fires_wildfires_forest_wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>419</td>\n",
       "      <td>6_gun_guns_shootings_mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>397</td>\n",
       "      <td>7_boomers_generation_gen_millennials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>357</td>\n",
       "      <td>8_crypto_bitcoin_energy_mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>329</td>\n",
       "      <td>9_population_overpopulation_resources_growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>283</td>\n",
       "      <td>10_private_jets_jet_flying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>252</td>\n",
       "      <td>11_fight_fighting_combat_fights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>248</td>\n",
       "      <td>12_refugees_migration_refugee_immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>219</td>\n",
       "      <td>13_insects_bugs_bees_insect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>215</td>\n",
       "      <td>14_manchin_senate_joe_democrats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>205</td>\n",
       "      <td>15_white_racism_black_racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>200</td>\n",
       "      <td>16_denial_denying_deny_denialism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>170</td>\n",
       "      <td>17_musk_elon_tesla_spacex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>18_video_kurzgesagt_videos_channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>138</td>\n",
       "      <td>19_game_games_halo_play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>132</td>\n",
       "      <td>20_painting_art_lisa_mona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>126</td>\n",
       "      <td>21_man_manmade_real_believe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>123</td>\n",
       "      <td>22_geoengineering_chemtrails_trails_srm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>109</td>\n",
       "      <td>23_denier_deniers_relegious_desmog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>109</td>\n",
       "      <td>24_masks_mask_masking_wearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>103</td>\n",
       "      <td>25_believe_don_believing_doesn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>102</td>\n",
       "      <td>26_elon_company_tesla_electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>101</td>\n",
       "      <td>27_ai_agi_humans_human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>97</td>\n",
       "      <td>28_ireland_irish_dublin_whiokf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>93</td>\n",
       "      <td>29_stop_stopping_did_need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>91</td>\n",
       "      <td>30_greta_thunberg_moxx_girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>87</td>\n",
       "      <td>31_eruption_volcano_volcanic_volcanoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>86</td>\n",
       "      <td>32_smoking_tobacco_smoke_weed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>81</td>\n",
       "      <td>33_fish_fishing_fisheries_overfishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>79</td>\n",
       "      <td>34_nfts_nft_blockchain_ethereum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>77</td>\n",
       "      <td>35_flat_earth_earthers_round</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>77</td>\n",
       "      <td>36_retirement_retire_ll_plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>76</td>\n",
       "      <td>37_coffee_chocolate_starbucks_roaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38</td>\n",
       "      <td>74</td>\n",
       "      <td>38_conspiracy_theories_theory_qanon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>39</td>\n",
       "      <td>73</td>\n",
       "      <td>39_heart_attacks_myocarditis_attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>40_models_model_climate_warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>41_queen_royal_palace_lobbied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42</td>\n",
       "      <td>72</td>\n",
       "      <td>42_solved_solve_solving_whoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>43</td>\n",
       "      <td>69</td>\n",
       "      <td>43_student_debt_loan_loans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>44_reverse_reversed_return_slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>45_ipcc_report_projections_ssp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>46</td>\n",
       "      <td>61</td>\n",
       "      <td>46_ticks_tick_lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>47_effects_effect_disastrous_impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>48_methane_atmosphere_hydrates_hydrate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                          Name\n",
       "0      -1  49437                   -1_people_just_like_climate\n",
       "1       0  38326                        0_people_like_just_don\n",
       "2       1   1190      1_protest_protests_protesting_protesters\n",
       "3       2    704                   2_god_church_religion_bible\n",
       "4       3    593           3_plastic_recycling_plastics_straws\n",
       "5       4    577                      4_trans_gender_women_men\n",
       "6       5    464             5_fires_wildfires_forest_wildfire\n",
       "7       6    419                     6_gun_guns_shootings_mass\n",
       "8       7    397          7_boomers_generation_gen_millennials\n",
       "9       8    357                8_crypto_bitcoin_energy_mining\n",
       "10      9    329  9_population_overpopulation_resources_growth\n",
       "11     10    283                    10_private_jets_jet_flying\n",
       "12     11    252               11_fight_fighting_combat_fights\n",
       "13     12    248     12_refugees_migration_refugee_immigration\n",
       "14     13    219                   13_insects_bugs_bees_insect\n",
       "15     14    215               14_manchin_senate_joe_democrats\n",
       "16     15    205                  15_white_racism_black_racist\n",
       "17     16    200              16_denial_denying_deny_denialism\n",
       "18     17    170                     17_musk_elon_tesla_spacex\n",
       "19     18    150            18_video_kurzgesagt_videos_channel\n",
       "20     19    138                       19_game_games_halo_play\n",
       "21     20    132                     20_painting_art_lisa_mona\n",
       "22     21    126                   21_man_manmade_real_believe\n",
       "23     22    123       22_geoengineering_chemtrails_trails_srm\n",
       "24     23    109            23_denier_deniers_relegious_desmog\n",
       "25     24    109                 24_masks_mask_masking_wearing\n",
       "26     25    103                25_believe_don_believing_doesn\n",
       "27     26    102                26_elon_company_tesla_electric\n",
       "28     27    101                        27_ai_agi_humans_human\n",
       "29     28     97                28_ireland_irish_dublin_whiokf\n",
       "30     29     93                     29_stop_stopping_did_need\n",
       "31     30     91                   30_greta_thunberg_moxx_girl\n",
       "32     31     87        31_eruption_volcano_volcanic_volcanoes\n",
       "33     32     86                 32_smoking_tobacco_smoke_weed\n",
       "34     33     81         33_fish_fishing_fisheries_overfishing\n",
       "35     34     79               34_nfts_nft_blockchain_ethereum\n",
       "36     35     77                  35_flat_earth_earthers_round\n",
       "37     36     77                  36_retirement_retire_ll_plan\n",
       "38     37     76         37_coffee_chocolate_starbucks_roaster\n",
       "39     38     74           38_conspiracy_theories_theory_qanon\n",
       "40     39     73           39_heart_attacks_myocarditis_attack\n",
       "41     40     73               40_models_model_climate_warming\n",
       "42     41     72                 41_queen_royal_palace_lobbied\n",
       "43     42     72                  42_solved_solve_solving_whoa\n",
       "44     43     69                    43_student_debt_loan_loans\n",
       "45     44     64               44_reverse_reversed_return_slow\n",
       "46     45     63                45_ipcc_report_projections_ssp\n",
       "47     46     61                    46_ticks_tick_lyme_disease\n",
       "48     47     61           47_effects_effect_disastrous_impact\n",
       "49     48     60        48_methane_atmosphere_hydrates_hydrate"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if model training was succesful\n",
    "topic_models[\"model_2022\"].get_topic_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as CSV file\n",
    "for year in range(2010, 2023):\n",
    "    model_name = f\"model_{year}\"\n",
    "    docs_name = f\"docs_{year}\"\n",
    "    file_name = f\"data/model{year}.csv\"\n",
    "    topic_models[model_name].get_document_info(globals()[docs_name]).to_csv(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Topic information as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as CSV file\n",
    "for year in range(2010, 2023):\n",
    "    model_name = f\"model_{year}\"\n",
    "    file_name = f\"data/topics_{year}.csv\"\n",
    "    topic_models[model_name].get_topic_info().to_csv(file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Dataset with Detected Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2010, 2023):\n",
    "    # Create dataframes to be joined and drop irrelevant columns from topic dataframe, set indexes for join\n",
    "    topic_data = topic_models[f\"model_{year}\"].get_document_info(globals()[f\"docs_{year}\"])\n",
    "    topic_data = topic_data.drop([\"Document\",\"Probability\",\"Representative_document\"], axis=1).reset_index()\n",
    "\n",
    "    original_data = year_dfs[f\"comments_{year}\"].reset_index(drop=True).reset_index()\n",
    "\n",
    "    # Join Columns\n",
    "    joined_df = original_data.join(topic_data,on='index',how='left',rsuffix='_topics')\n",
    "\n",
    "    # Set the name of the joined dataframe\n",
    "    joined_df_name = f\"joined_{year}\"\n",
    "\n",
    "    # Add the joined dataframe to the global namespace\n",
    "    globals()[joined_df_name] = joined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting all dataframes back together\n",
    "# List of joined dataframe names\n",
    "joined_df_names = [f\"joined_{year}\" for year in range(2010, 2023)]\n",
    "\n",
    "# List of joined dataframes\n",
    "joined_dfs = [globals()[df_name] for df_name in joined_df_names]\n",
    "\n",
    "# Concatenate the joined dataframes row-wise\n",
    "concatenated_df = pd.concat(joined_dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop and rename columns\n",
    "concatenated_df = concatenated_df.drop([\"index\", \"index_topics\"], axis=1)\n",
    "concatenated_df = concatenated_df.rename(columns={'Topic': 'topic_number', 'Name': 'topic_name', 'Top_n_words': 'topic_most_used_words'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Document with Topic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv(\"data/comments_with_topics.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Topic File & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/comments_with_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort out all outlier topics\n",
    "test = test[test[\"Topic\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          int64\n",
       "index               int64\n",
       "id                 object\n",
       "subreddit.name     object\n",
       "subreddit.nsfw       bool\n",
       "created_utc       float64\n",
       "permalink          object\n",
       "sentiment         float64\n",
       "score             float64\n",
       "created_date       object\n",
       "created_day         int64\n",
       "created_month       int64\n",
       "created_year        int64\n",
       "created_time       object\n",
       "body_clean         object\n",
       "index_topics        int64\n",
       "Topic               int64\n",
       "Name               object\n",
       "Top_n_words        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to understand if topic detection worked\n",
    "test.head()\n",
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit.name</th>\n",
       "      <th>subreddit.nsfw</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_time</th>\n",
       "      <th>body_clean</th>\n",
       "      <th>index_topics</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>c1b02v0</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>1.293838e+09</td>\n",
       "      <td>https://old.reddit.com/r/worldnews/comments/eu...</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>23:25:47</td>\n",
       "      <td>This is true but only because Australia lacks ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0_people_just_climate_global</td>\n",
       "      <td>people - just - climate - global - don - like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15987</th>\n",
       "      <td>15987</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ct514</td>\n",
       "      <td>politics</td>\n",
       "      <td>False</td>\n",
       "      <td>1.325370e+09</td>\n",
       "      <td>https://old.reddit.com/r/politics/comments/nxl...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2011</td>\n",
       "      <td>22:12:09</td>\n",
       "      <td>I don't think we can even say that states with...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_climate_people_just_global</td>\n",
       "      <td>climate - people - just - global - warming - d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42419</th>\n",
       "      <td>42419</td>\n",
       "      <td>1</td>\n",
       "      <td>c7ozhxj</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>False</td>\n",
       "      <td>1.356997e+09</td>\n",
       "      <td>https://old.reddit.com/r/todayilearned/comment...</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2012</td>\n",
       "      <td>23:41:16</td>\n",
       "      <td>The added pressures of human activity(killing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_climate_just_warming</td>\n",
       "      <td>people - climate - just - warming - global - l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90097</th>\n",
       "      <td>90097</td>\n",
       "      <td>1</td>\n",
       "      <td>ceefasa</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>False</td>\n",
       "      <td>1.388533e+09</td>\n",
       "      <td>https://old.reddit.com/r/worldnews/comments/1u...</td>\n",
       "      <td>-0.2799</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>23:35:31</td>\n",
       "      <td>Yeah but perhaps the fear of nuclear war promp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0_ted_headed_seen_talk</td>\n",
       "      <td>ted - headed - seen - talk - level - ve - news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249425</th>\n",
       "      <td>249425</td>\n",
       "      <td>1</td>\n",
       "      <td>chnzed1</td>\n",
       "      <td>iama</td>\n",
       "      <td>False</td>\n",
       "      <td>1.400719e+09</td>\n",
       "      <td>https://old.reddit.com/r/IAmA/comments/264vkr/...</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-05-22</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>00:33:04</td>\n",
       "      <td>; Who or what funds most of this kind of resea...</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>28_funding_grant_money_research</td>\n",
       "      <td>funding - grant - money - research - grants - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375229</th>\n",
       "      <td>375229</td>\n",
       "      <td>1</td>\n",
       "      <td>cs0ya46</td>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>False</td>\n",
       "      <td>1.433880e+09</td>\n",
       "      <td>https://old.reddit.com/r/climateskeptics/comme...</td>\n",
       "      <td>-0.8716</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>19:55:34</td>\n",
       "      <td>I'm shocked and disturbed that almost two thir...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_climate_people_science_just</td>\n",
       "      <td>climate - people - science - just - like - don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474779</th>\n",
       "      <td>474779</td>\n",
       "      <td>1</td>\n",
       "      <td>d8o47oy</td>\n",
       "      <td>politics</td>\n",
       "      <td>False</td>\n",
       "      <td>1.476232e+09</td>\n",
       "      <td>https://old.reddit.com/r/politics/comments/570...</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2016</td>\n",
       "      <td>00:27:02</td>\n",
       "      <td>It amazes me that , vaccines, and evolution ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7_vaccines_autism_vaccine_anti</td>\n",
       "      <td>vaccines - autism - vaccine - anti - vaxxers -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574368</th>\n",
       "      <td>574368</td>\n",
       "      <td>1</td>\n",
       "      <td>drwiffg</td>\n",
       "      <td>politics</td>\n",
       "      <td>False</td>\n",
       "      <td>1.514540e+09</td>\n",
       "      <td>https://old.reddit.com/r/politics/comments/7mr...</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>09:30:37</td>\n",
       "      <td>The label flipped to , because they realized t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0_people_like_just_don</td>\n",
       "      <td>people - like - just - don - trump - think - c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673912</th>\n",
       "      <td>673912</td>\n",
       "      <td>1</td>\n",
       "      <td>e5gzsna</td>\n",
       "      <td>earthporn</td>\n",
       "      <td>False</td>\n",
       "      <td>1.536199e+09</td>\n",
       "      <td>https://old.reddit.com/r/EarthPorn/comments/9d...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>01:57:24</td>\n",
       "      <td>For a sense of scale look very closely at the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_climate_just_like</td>\n",
       "      <td>people - climate - just - like - don - think -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773403</th>\n",
       "      <td>773403</td>\n",
       "      <td>1</td>\n",
       "      <td>ej1rlo0</td>\n",
       "      <td>politics</td>\n",
       "      <td>False</td>\n",
       "      <td>1.553185e+09</td>\n",
       "      <td>https://old.reddit.com/r/politics/comments/b3p...</td>\n",
       "      <td>-0.9844</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>16:19:01</td>\n",
       "      <td>Of course there's a connection. Which one do w...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_climate_people_just_like</td>\n",
       "      <td>climate - people - just - like - don - change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872822</th>\n",
       "      <td>872822</td>\n",
       "      <td>1</td>\n",
       "      <td>g8v7e2y</td>\n",
       "      <td>futurology</td>\n",
       "      <td>False</td>\n",
       "      <td>1.602733e+09</td>\n",
       "      <td>https://old.reddit.com/r/Futurology/comments/j...</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>03:38:55</td>\n",
       "      <td>Thank you for the response. My view is that re...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0_people_just_like_don</td>\n",
       "      <td>people - just - like - don - think - biden - t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972253</th>\n",
       "      <td>972253</td>\n",
       "      <td>1</td>\n",
       "      <td>hkrr8ry</td>\n",
       "      <td>politicalcompass</td>\n",
       "      <td>False</td>\n",
       "      <td>1.637012e+09</td>\n",
       "      <td>https://old.reddit.com/r/PoliticalCompass/comm...</td>\n",
       "      <td>-0.5859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>21:28:46</td>\n",
       "      <td>Oh boohoo muh gas prices. Gas prices were arti...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_just_like_climate</td>\n",
       "      <td>people - just - like - climate - don - think -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071585</th>\n",
       "      <td>1071585</td>\n",
       "      <td>1</td>\n",
       "      <td>hz51unj</td>\n",
       "      <td>technews</td>\n",
       "      <td>False</td>\n",
       "      <td>1.646280e+09</td>\n",
       "      <td>https://old.reddit.com/r/technews/comments/t53...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>03:54:08</td>\n",
       "      <td>Were never going to reopen those wells, its e...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_people_just_like_climate</td>\n",
       "      <td>people - just - like - climate - don - think -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  index       id    subreddit.name  subreddit.nsfw   \n",
       "1                 1      1  c1b02v0         worldnews           False  \\\n",
       "15987         15987      1  c3ct514          politics           False   \n",
       "42419         42419      1  c7ozhxj     todayilearned           False   \n",
       "90097         90097      1  ceefasa         worldnews           False   \n",
       "249425       249425      1  chnzed1              iama           False   \n",
       "375229       375229      1  cs0ya46   climateskeptics           False   \n",
       "474779       474779      1  d8o47oy          politics           False   \n",
       "574368       574368      1  drwiffg          politics           False   \n",
       "673912       673912      1  e5gzsna         earthporn           False   \n",
       "773403       773403      1  ej1rlo0          politics           False   \n",
       "872822       872822      1  g8v7e2y        futurology           False   \n",
       "972253       972253      1  hkrr8ry  politicalcompass           False   \n",
       "1071585     1071585      1  hz51unj          technews           False   \n",
       "\n",
       "          created_utc                                          permalink   \n",
       "1        1.293838e+09  https://old.reddit.com/r/worldnews/comments/eu...  \\\n",
       "15987    1.325370e+09  https://old.reddit.com/r/politics/comments/nxl...   \n",
       "42419    1.356997e+09  https://old.reddit.com/r/todayilearned/comment...   \n",
       "90097    1.388533e+09  https://old.reddit.com/r/worldnews/comments/1u...   \n",
       "249425   1.400719e+09  https://old.reddit.com/r/IAmA/comments/264vkr/...   \n",
       "375229   1.433880e+09  https://old.reddit.com/r/climateskeptics/comme...   \n",
       "474779   1.476232e+09  https://old.reddit.com/r/politics/comments/570...   \n",
       "574368   1.514540e+09  https://old.reddit.com/r/politics/comments/7mr...   \n",
       "673912   1.536199e+09  https://old.reddit.com/r/EarthPorn/comments/9d...   \n",
       "773403   1.553185e+09  https://old.reddit.com/r/politics/comments/b3p...   \n",
       "872822   1.602733e+09  https://old.reddit.com/r/Futurology/comments/j...   \n",
       "972253   1.637012e+09  https://old.reddit.com/r/PoliticalCompass/comm...   \n",
       "1071585  1.646280e+09  https://old.reddit.com/r/technews/comments/t53...   \n",
       "\n",
       "         sentiment  score created_date  created_day  created_month   \n",
       "1          -0.2263   16.0   2010-12-31           31             12  \\\n",
       "15987       0.8020    0.0   2011-12-31           31             12   \n",
       "42419       0.4904    4.0   2012-12-31           31             12   \n",
       "90097      -0.2799    5.0   2013-12-31           31             12   \n",
       "249425      0.9497    1.0   2014-05-22           22              5   \n",
       "375229     -0.8716    6.0   2015-06-09            9              6   \n",
       "474779      0.6705    1.0   2016-10-12           12             10   \n",
       "574368      0.6801   18.0   2017-12-29           29             12   \n",
       "673912     -0.3400    1.0   2018-09-06            6              9   \n",
       "773403     -0.9844    3.0   2019-03-21           21              3   \n",
       "872822      0.7057    1.0   2020-10-15           15             10   \n",
       "972253     -0.5859    1.0   2021-11-15           15             11   \n",
       "1071585     0.4588    1.0   2022-03-03            3              3   \n",
       "\n",
       "         created_year created_time   \n",
       "1                2010     23:25:47  \\\n",
       "15987            2011     22:12:09   \n",
       "42419            2012     23:41:16   \n",
       "90097            2013     23:35:31   \n",
       "249425           2014     00:33:04   \n",
       "375229           2015     19:55:34   \n",
       "474779           2016     00:27:02   \n",
       "574368           2017     09:30:37   \n",
       "673912           2018     01:57:24   \n",
       "773403           2019     16:19:01   \n",
       "872822           2020     03:38:55   \n",
       "972253           2021     21:28:46   \n",
       "1071585          2022     03:54:08   \n",
       "\n",
       "                                                body_clean  index_topics   \n",
       "1        This is true but only because Australia lacks ...             1  \\\n",
       "15987    I don't think we can even say that states with...             1   \n",
       "42419    The added pressures of human activity(killing ...             1   \n",
       "90097    Yeah but perhaps the fear of nuclear war promp...             1   \n",
       "249425   ; Who or what funds most of this kind of resea...             1   \n",
       "375229   I'm shocked and disturbed that almost two thir...             1   \n",
       "474779   It amazes me that , vaccines, and evolution ha...             1   \n",
       "574368   The label flipped to , because they realized t...             1   \n",
       "673912   For a sense of scale look very closely at the ...             1   \n",
       "773403   Of course there's a connection. Which one do w...             1   \n",
       "872822   Thank you for the response. My view is that re...             1   \n",
       "972253   Oh boohoo muh gas prices. Gas prices were arti...             1   \n",
       "1071585  Were never going to reopen those wells, its e...             1   \n",
       "\n",
       "         Topic                             Name   \n",
       "1            0     0_people_just_climate_global  \\\n",
       "15987       -1    -1_climate_people_just_global   \n",
       "42419       -1   -1_people_climate_just_warming   \n",
       "90097        0           0_ted_headed_seen_talk   \n",
       "249425      28  28_funding_grant_money_research   \n",
       "375229      -1   -1_climate_people_science_just   \n",
       "474779       7   7_vaccines_autism_vaccine_anti   \n",
       "574368       0           0_people_like_just_don   \n",
       "673912      -1      -1_people_climate_just_like   \n",
       "773403      -1      -1_climate_people_just_like   \n",
       "872822       0           0_people_just_like_don   \n",
       "972253      -1      -1_people_just_like_climate   \n",
       "1071585     -1      -1_people_just_like_climate   \n",
       "\n",
       "                                               Top_n_words  \n",
       "1        people - just - climate - global - don - like ...  \n",
       "15987    climate - people - just - global - warming - d...  \n",
       "42419    people - climate - just - warming - global - l...  \n",
       "90097    ted - headed - seen - talk - level - ve - news...  \n",
       "249425   funding - grant - money - research - grants - ...  \n",
       "375229   climate - people - science - just - like - don...  \n",
       "474779   vaccines - autism - vaccine - anti - vaxxers -...  \n",
       "574368   people - like - just - don - trump - think - c...  \n",
       "673912   people - climate - just - like - don - think -...  \n",
       "773403   climate - people - just - like - don - change ...  \n",
       "872822   people - just - like - don - think - biden - t...  \n",
       "972253   people - just - like - climate - don - think -...  \n",
       "1071585  people - just - like - climate - don - think -...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"index\"] == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
